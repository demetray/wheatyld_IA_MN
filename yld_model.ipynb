{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in annual wheat yields data\n",
    "path = '/Users/demetrayancopoulos/Desktop/SML310/final_project/gro_ylds/wheatf_mn_ia.xlsx'\n",
    "y = pd.read_excel(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in features data\n",
    "path = '/Users/demetrayancopoulos/Desktop/SML310/final_project/finalfeat.xlsx'\n",
    "x = pd.read_excel(path)\n",
    "x.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# normalize all features (so that each feature has equal weight in model)\n",
    "x = (x-x.min())/(x.max()-x.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a04b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into training, testing and validation set\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y['Value'], test_size = 0.25)\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbe1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to examine performance on test set, set xtest, ytest --> xval, yval\n",
    "test = 0\n",
    "\n",
    "if test:\n",
    "    xval = xtest\n",
    "    yval = ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df681a41",
   "metadata": {},
   "source": [
    "# Multivariate linear regression with manual feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb939e",
   "metadata": {},
   "source": [
    "## Initialize linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c3a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column of constants, so that residual mean can be centered at zero\n",
    "xtrainc = sm.add_constant(xtrain)\n",
    "\n",
    "# get linear regression with all features\n",
    "lr = sm.OLS(ytrain, xtrainc).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327eeff1",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a4055",
   "metadata": {},
   "source": [
    "Drop insignificant features (P > threshold)\n",
    "\n",
    "https://online.stat.psu.edu/stat462/node/180/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set maximum allowed p value\n",
    "pthresh = 0.01\n",
    "\n",
    "# get maximum p value in the current linear regression model\n",
    "pmax = lr.pvalues.max()\n",
    "\n",
    "# as long as the largest p value is greater than pthresh, drop \n",
    "# the feature with largest p value\n",
    "while pmax > pthresh:\n",
    "    \n",
    "    # drop feature with highest p value\n",
    "    imax = lr.pvalues.idxmax()\n",
    "    xtrainc = xtrainc.drop(imax,1)\n",
    "    \n",
    "    # build new model now that a feature has been dropped\n",
    "    lr = sm.OLS(ytrain, xtrainc).fit()\n",
    "    \n",
    "    # find highest p value in the new model\n",
    "    pmax = lr.pvalues.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697520f",
   "metadata": {},
   "source": [
    "Check for multicollinearity between the features using variance inflation factor\n",
    "\n",
    "https://etav.github.io/python/vif_factor_python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as viff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03780ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dataframe to store features and their VIFs\n",
    "col = {'Explanatory var':[], 'VIF':[]}\n",
    "vif = pd.DataFrame(data=col)\n",
    "\n",
    "# get initial VIF for each feature\n",
    "ncol = len(xtrainc.columns)\n",
    "for i in range(0, ncol):\n",
    "    vif = vif.append({'Explanatory var':xtrainc.columns[i], 'VIF':viff(xtrainc.values, i)}, ignore_index=True)\n",
    "\n",
    "# set maximum allowed vif\n",
    "vifthresh = 50\n",
    "\n",
    "# get maximum VIF to see if any features exceed threshold\n",
    "vifmax = vif['VIF'].max()\n",
    "\n",
    "# as long as max feature is above allowed threshold, drop that feature, and generate a new model\n",
    "# (MODEL IMPROVES AS VIFMAX INC --> ie more features, better accuracy)\n",
    "while vifmax > vifthresh:\n",
    "\n",
    "    # drop variable with highest VIF\n",
    "    imax = vif[['VIF']].idxmax()\n",
    "    drp = vif['Explanatory var'][imax]\n",
    "    xtrainc = xtrainc.drop(drp,1)\n",
    "    \n",
    "    # build new model now that a feature has been dropped\n",
    "    lr = sm.OLS(ytrain, xtrainc).fit()\n",
    "\n",
    "    # recalculate VIF for each feature\n",
    "    vif = pd.DataFrame(data=col)\n",
    "    ncol = xtrainc.shape[1]\n",
    "    for i in range(0, ncol):\n",
    "        vif = vif.append({'Explanatory var':xtrainc.columns[i], 'VIF':viff(xtrainc.values, i)}, ignore_index=True)\n",
    "    \n",
    "    vifmax = vif['VIF'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302be36e",
   "metadata": {},
   "source": [
    "Now that all p values are within threshold significance level, and VIF for each feature is within allowed threshold (ie. all features are linearly independent), inspect whether the residual on training set are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee497cc",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86439bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions from training set \n",
    "ypred_train = lr.predict(xtrainc)\n",
    "\n",
    "# plot residuals of training predictions of yield to actual yields \n",
    "plt.hist(ytrain-ypred_train, bins = 15)\n",
    "plt.suptitle('Residuals of training predictions of yield to actual yields \\n for multivariate linear regression with manual feature selection')\n",
    "plt.xlabel('Residuals [tonnes per ha]')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b940ce",
   "metadata": {},
   "source": [
    "Examine predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constant variable to center residuals around zero\n",
    "xvalt = sm.add_constant(xval)\n",
    "\n",
    "# cols remaining in the training set after feature selection\n",
    "colskept = xtrainc.columns\n",
    "\n",
    "# make a final validation x set containing only the features \n",
    "# selected based on training set feature selection\n",
    "xvalc = pd.DataFrame()\n",
    "for col in colskept:\n",
    "    temp = xvalt.pop(col)\n",
    "    xvalc = pd.concat([xvalc, temp], axis=1)\n",
    "\n",
    "# examine predictions on validation set\n",
    "ypred_val = lr.predict(xvalc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deed13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare r^2 on training set and test set\n",
    "r2_val = r2_score(y_true = yval, y_pred = ypred_val)\n",
    "r2_train = r2_score(y_true = ytrain, y_pred = ypred_train)\n",
    "\n",
    "# get MSE on training set and test set\n",
    "mse_val = mean_squared_error(yval, ypred_val)\n",
    "mse_train = mean_squared_error(ytrain, ypred_train)\n",
    "\n",
    "print('r2_val: ', r2_val)\n",
    "print('r2_train: ', r2_train)\n",
    "\n",
    "print('MSE val: ', mse_val)\n",
    "print('MSE train: ', mse_train)\n",
    "\n",
    "print('Number of features: ', len(xtrainc.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46ba1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9065adb9",
   "metadata": {},
   "source": [
    "# Multivariate linear regression with variance threshold feature selection\n",
    "https://towardsdatascience.com/5-feature-selection-method-from-scikit-learn-you-should-know-ed4d116e4172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62450cc",
   "metadata": {},
   "source": [
    "## Feature selection: variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e75ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variance threshold\n",
    "varthresh = 0.02\n",
    "\n",
    "# select features based on variance threshold\n",
    "selector = VarianceThreshold(varthresh)\n",
    "selector.fit(xtrain)\n",
    "\n",
    "# compile selected features for the training and validation sets\n",
    "xtrainc=xtrain[xtrain.columns[selector.get_support()]]\n",
    "xvalc=xval[xtrain.columns[selector.get_support()]]\n",
    "\n",
    "# initialize linear regression model based on the training set\n",
    "lr = sm.OLS(ytrain, xtrainc).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29884ba",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f98af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions from training set \n",
    "ypred_train = lr.predict(xtrainc)\n",
    "# calculate predictions from validation set\n",
    "ypred_val = lr.predict(xvalc)\n",
    "\n",
    "# plot residuals of training predictions of yield to actual yields \n",
    "plt.hist(ytrain-ypred_train, bins = 15)\n",
    "plt.suptitle('Residuals of training predictions of yield to actual yields \\n for multivariate linear regression with variance threshold feature selection')\n",
    "plt.xlabel('Residuals [tonnes per ha]')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare r^2 on training set and test set\n",
    "r2_val = r2_score(y_true = yval, y_pred = ypred_val)\n",
    "r2_train = r2_score(y_true = ytrain, y_pred = ypred_train)\n",
    "\n",
    "# get MSE on training set and test set\n",
    "mse_val = mean_squared_error(yval, ypred_val)\n",
    "mse_train = mean_squared_error(ytrain, ypred_train)\n",
    "\n",
    "print('r2_val: ', r2_val)\n",
    "print('r2_train: ', r2_train)\n",
    "\n",
    "print('MSE val: ', mse_val)\n",
    "print('MSE train: ', mse_train)\n",
    "\n",
    "print('Number of features: ', len(xtrainc.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50037aa",
   "metadata": {},
   "source": [
    "# Multivariate linear regression with recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a20079",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4baabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897586f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of features to select\n",
    "nfeat = 30\n",
    "\n",
    "# select features using RFE\n",
    "selector = RFE(estimator=LinearRegression(), n_features_to_select=nfeat, step=1)\n",
    "selector.fit(xtrain, ytrain)\n",
    "\n",
    "# get training set with selected features\n",
    "xtrainc = xtrain[xtrain.columns[selector.get_support()]]\n",
    "# get validation set with selected features\n",
    "xvalc = xval[xtrain.columns[selector.get_support()]]\n",
    "\n",
    "# initialize linear regression model\n",
    "lr = sm.OLS(ytrain, xtrainc).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52058d3",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5876de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions from training set \n",
    "ypred_train = lr.predict(xtrainc)\n",
    "# calculate predictions from validation set\n",
    "ypred_val = lr.predict(xvalc)\n",
    "\n",
    "# plot residuals of training predictions of yield to actual yields \n",
    "plt.hist(ytrain-ypred_train, bins = 15)\n",
    "plt.suptitle('Residuals of training predictions of yield to actual yields \\n for multivariate linear regression with recursive feature elimination')\n",
    "plt.xlabel('Residuals [tonnes per ha]')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1222d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare r^2 on training set and test set\n",
    "r2_val = r2_score(y_true = yval, y_pred = ypred_val)\n",
    "r2_train = r2_score(y_true = ytrain, y_pred = ypred_train)\n",
    "\n",
    "# get MSE on training set and test set\n",
    "mse_val = mean_squared_error(yval, ypred_val)\n",
    "mse_train = mean_squared_error(ytrain, ypred_train)\n",
    "\n",
    "print('r2_val: ', r2_val)\n",
    "print('r2_train: ', r2_train)\n",
    "\n",
    "print('MSE val: ', mse_val)\n",
    "print('MSE train: ', mse_train)\n",
    "print('Number of features: ', len(xtrainc.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874526fb",
   "metadata": {},
   "source": [
    "# Multivariable linear regression with sequential feature selection\n",
    "\n",
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of features to select\n",
    "nfeat = 30\n",
    "\n",
    "# select features using sequential feature selection\n",
    "selector = SequentialFeatureSelector(estimator=LinearRegression(), n_features_to_select = nfeat, direction = 'backward')\n",
    "selector.fit(xtrain, ytrain)\n",
    "\n",
    "# get training set with selected features\n",
    "xtrainc = xtrain[xtrain.columns[selector.get_support()]]\n",
    "# get validation set with selected features\n",
    "xvalc = xval[xtrain.columns[selector.get_support()]]\n",
    "\n",
    "# initialize linear regression model\n",
    "lr = sm.OLS(ytrain, xtrainc).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a281d5a",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c132f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate predictions from training set \n",
    "ypred_train = lr.predict(xtrainc)\n",
    "# calculate predictions from validation set\n",
    "ypred_val = lr.predict(xvalc)\n",
    "\n",
    "# plot residuals of training predictions of yield to actual yields \n",
    "plt.hist(ytrain-ypred_train, bins = 15)\n",
    "plt.suptitle('Residuals of training predictions of yield to actual yields \\n for multivariate linear regression with sequential feature selection')\n",
    "plt.xlabel('Residuals [tonnes per ha]')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9cd707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare r^2 on training set and test set\n",
    "r2_val = r2_score(y_true = yval, y_pred = ypred_val)\n",
    "r2_train = r2_score(y_true = ytrain, y_pred = ypred_train)\n",
    "\n",
    "# get MSE on training set and test set\n",
    "mse_val = mean_squared_error(yval, ypred_val)\n",
    "mse_train = mean_squared_error(ytrain, ypred_train)\n",
    "\n",
    "print('r2_val: ', r2_val)\n",
    "print('r2_train: ', r2_train)\n",
    "\n",
    "print('MSE val: ', mse_val)\n",
    "print('MSE train: ', mse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e9292",
   "metadata": {},
   "source": [
    "# Multivariate polynomial regression: select features with sequential feature selection (before transforming to polynomial features)\n",
    "https://www.askpython.com/python/examples/polynomial-regression-in-python\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e492c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d36c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of features to select\n",
    "nfeat = 10\n",
    "\n",
    "# select features using sequential feature selection\n",
    "selector = SequentialFeatureSelector(estimator=LinearRegression(), n_features_to_select = nfeat, direction = 'backward')\n",
    "selector.fit(xtrain, ytrain)\n",
    "\n",
    "# get training set with selected features\n",
    "xtrainc1 = xtrain[xtrain.columns[selector.get_support()]]\n",
    "# get validation set with selected features\n",
    "xvalc1 = xval[xtrain.columns[selector.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize polynomial model (get all polynomial features up to deg 2)\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# get the new training and validation sets \n",
    "xtrainc = poly.fit_transform(xtrainc1)\n",
    "xvalc = poly.fit_transform(xvalc1)\n",
    "\n",
    "# get all the new feature names\n",
    "newcols = poly.get_feature_names_out(input_features=xtrainc1.columns)\n",
    "\n",
    "# convert new training and validation sets into dataframes\n",
    "xtrainc = pd.DataFrame(xtrainc, columns = newcols)\n",
    "xvalc = pd.DataFrame(xvalc, columns = newcols)\n",
    "\n",
    "# initialize linear regression now that features contain deg 2 polynomial\n",
    "lr = sm.OLS(ytrain.values, xtrainc.values).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd606a",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions from training set \n",
    "ypred_train = lr.predict(xtrainc)\n",
    "# calculate predictions from validation set\n",
    "ypred_val = lr.predict(xvalc)\n",
    "\n",
    "# plot residuals of training predictions of yield to actual yields \n",
    "plt.hist(ytrain-ypred_train, bins = 15)\n",
    "plt.suptitle('Residuals of training predictions of yield to actual yields \\n for variance thresh feat selection THEN multivariate poly (deg2) regression')\n",
    "plt.xlabel('Residuals [tonnes per ha]')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare r^2 on training set and test set\n",
    "r2_val = r2_score(y_true = yval, y_pred = ypred_val)\n",
    "r2_train = r2_score(y_true = ytrain, y_pred = ypred_train)\n",
    "\n",
    "# get MSE on training set and test set\n",
    "mse_val = mean_squared_error(yval, ypred_val)\n",
    "mse_train = mean_squared_error(ytrain, ypred_train)\n",
    "\n",
    "print('r2_val: ', r2_val)\n",
    "print('r2_train: ', r2_train)\n",
    "\n",
    "print('MSE val: ', mse_val)\n",
    "print('MSE train: ', mse_train)\n",
    "print('Number of features: ', len(xtrainc.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9fcdb",
   "metadata": {},
   "source": [
    "# Multivariate polynomial regression: select features sequential feature selection (after transformation to polynomial features)\n",
    "\n",
    "## Initialize polynomial deg 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# get training and validation set values for deg 2 polynomial features\n",
    "xtrainc = poly.fit_transform(xtrain.values)\n",
    "xvalc = poly.fit_transform(xval.values)\n",
    "\n",
    "# get new feature names\n",
    "newcols = poly.get_feature_names_out(input_features=xtrain.columns)\n",
    "\n",
    "# create dataframes from new training and validation sets\n",
    "xtrainc = pd.DataFrame(xtrainc, columns = newcols)\n",
    "xvalc = pd.DataFrame(xvalc, columns = newcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bbd899",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6fb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variance threshold\n",
    "varthresh = 0.02\n",
    "\n",
    "# select features based on variance threshold\n",
    "selector = VarianceThreshold(varthresh)\n",
    "selector.fit(xtrain)\n",
    "\n",
    "# compile selected features for the training and validation sets\n",
    "xtrainc=xtrain[xtrain.columns[selector.get_support()]]\n",
    "xvalc=xval[xtrain.columns[selector.get_support()]]\n",
    "\n",
    "# initialize linear regression model\n",
    "lr = sm.OLS(ytrain, xtrainc).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9236b2",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ed579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions from training set \n",
    "ypred_train = lr.predict(xtrainc)\n",
    "# calculate predictions from validation set\n",
    "ypred_val = lr.predict(xvalc)\n",
    "\n",
    "\n",
    "# plot residuals of training predictions of yield to actual yields \n",
    "plt.hist(ytrain-ypred_train, bins = 15)\n",
    "plt.suptitle('Residuals of training predictions of yield to actual yields \\n for multivariate poly (deg=2) regression THEN var thresh feat selection')\n",
    "plt.xlabel('Residuals [tonnes per ha]')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare r^2 on training set and test set\n",
    "r2_val = r2_score(y_true = yval, y_pred = ypred_val)\n",
    "r2_train = r2_score(y_true = ytrain, y_pred = ypred_train)\n",
    "\n",
    "# get MSE on training set and test set\n",
    "mse_val = mean_squared_error(yval, ypred_val)\n",
    "mse_train = mean_squared_error(ytrain, ypred_train)\n",
    "\n",
    "print('r2_val: ', r2_val)\n",
    "print('r2_train: ', r2_train)\n",
    "\n",
    "print('MSE val: ', mse_val)\n",
    "print('MSE train: ', mse_train)\n",
    "print('Number of features: ', len(xtrainc.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
